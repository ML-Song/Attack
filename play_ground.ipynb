{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     11
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# prepare data\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "paths = list(glob.iglob('data/IJCAI_2019_AAAC_train/*/*'))\n",
    "for i, p in enumerate(paths):\n",
    "#     with open(p, 'rb') as f:\n",
    "#         image_bytes = f.read()\n",
    "#         image_bytes = exif_remove(image_bytes)\n",
    "#     iof = BytesIO()\n",
    "#     iof.write(image_bytes)\n",
    "    if p.endswith(('gif', )):\n",
    "        status[i] = False\n",
    "    image = Image.open(p)\n",
    "    x, y = image.size\n",
    "    if x < 30 or y < 30:\n",
    "        status[i] = False\n",
    "    if image.format == \"GIF\":\n",
    "        status[i] = False\n",
    "    if image.mode == 'RGBA':\n",
    "        status[i] = False\n",
    "    if image.mode != \"RGB\":\n",
    "        status[i] = False\n",
    "status = [True] * len(paths)\n",
    "paths = np.array(paths)\n",
    "paths = paths[status]\n",
    "labels = [int(p.split('/')[-2]) for p in paths]\n",
    "path_train, path_test, label_train, label_test = train_test_split(paths, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# GAIN API\n",
    "import cv2\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import pretrainedmodels\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from config_gain import *\n",
    "from models import drn, activations\n",
    "from models.gain import GAINSolver\n",
    "from models.classifier import ClassifierNet, Classifier\n",
    "\n",
    "for i in [i / 10 for i in range(-10, 10)]:\n",
    "# if __name__ == '__main__':\n",
    "#     i = 0\n",
    "    backbone = pretrainedmodels.__dict__[model_name]()\n",
    "    backbone = nn.Sequential(*list(backbone.children())[: -2])\n",
    "    solver = GAINSolver(backbone, num_classes, in_channels, devices=devices, \n",
    "                        activation=activations.HardConcrete(i, temp))\n",
    "    solver.load_model(\n",
    "        'saved_models/best_model_GAIN model: se_resnext50_32x4d optimizer: sgd loc: -0.3 temp: 0.1.pt')\n",
    "\n",
    "    model = pretrainedmodels.__dict__['inceptionresnetv2']()\n",
    "    net = ClassifierNet(model, 110)\n",
    "    classifier = Classifier(net, devices=devices)\n",
    "    classifier.load_model('saved_models/best_model_Classifier model: inceptionresnetv2.pt')\n",
    "\n",
    "    img = [Image.open(i) for i in glob.iglob('data/dev_data/*') if i.endswith('png')]\n",
    "    img_np = np.asarray([np.asarray(i) for i in img])\n",
    "\n",
    "    cls, mask = solver.predict(img)\n",
    "    mask = mask > 0.5\n",
    "    img_target = img_np.copy()\n",
    "    img_target[~mask.repeat(3, axis=-1)] = 0\n",
    "    num = mask.reshape(mask.shape[0], -1).sum(axis=-1)\n",
    "    num = num.reshape(mask.shape[0], 1, 1, 1).repeat(3, axis=-1)\n",
    "    img_mean = img_target.sum(axis=1, keepdims=True).sum(axis=2, keepdims=True) / num\n",
    "#     img_mean = img_np.mean(axis=1, keepdims=True).mean(axis=2, keepdims=True)\n",
    "    img_masked = (1 - mask) * img_np + mask * img_mean\n",
    "\n",
    "    gt = classifier.predict(img).argmax(axis=1)\n",
    "    pred = solver.predict([Image.fromarray(i) for i in img_masked.astype(np.uint8)])[0].argmax(axis=1)\n",
    "    true_index = gt == pred\n",
    "    score = true_index.sum() * 64 / gt.shape[0] + np.sqrt(np.square(img_masked - img_np)[~true_index].mean())\n",
    "    print('temp: {}, score: {}, acc: {}'.format(i, score, true_index.sum()/110.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     15
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import pretrainedmodels\n",
    "from config_gba import *\n",
    "from models.gradient_based_attack import Attack\n",
    "from models.classifier import ClassifierNet, Classifier\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, devices))\n",
    "    models = [pretrainedmodels.__dict__[name]() for name in classifier_name]\n",
    "    classifiers = [ClassifierNet(model, num_classes) for model in models]\n",
    "    for c, p in zip(classifiers, classifier_path):\n",
    "        c.load_state_dict(torch.load(p))\n",
    "        \n",
    "        \n",
    "    data = {'image_path': [], 'target': [], 'imgs': []}\n",
    "    with open(os.path.join(data_path, 'dev.csv'), 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            img_path = os.path.join(data_path, row['filename'])\n",
    "            data['image_path'].append(img_path)\n",
    "            data['imgs'].append(Image.open(img_path))\n",
    "            if targeted:\n",
    "                data['target'].append(int(row['targetedLabel']))\n",
    "            else:\n",
    "                data['target'].append(int(row['trueLabel']))\n",
    "    result = []\n",
    "    epoch = math.ceil(len(data['imgs']) / batch_size)\n",
    "\n",
    "    solver = Attack(classifiers[: -1], classifiers[-1: ], \n",
    "                    device='cuda', patience=patience, max_iteration=max_iteration)\n",
    "    for i in tqdm.tqdm(range(epoch), total=epoch):\n",
    "        torch.cuda.empty_cache()\n",
    "        batch_x = data['imgs'][i * batch_size: (i + 1) * batch_size]\n",
    "        batch_y = data['target'][i * batch_size: (i + 1) * batch_size]\n",
    "        result.extend(solver.predict(batch_x, batch_y, targeted, max_perturbation=max_perturbation, lr=lr))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import os\n",
    "import math\n",
    "import torch\n",
    "import torchvision as tv\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import pretrainedmodels\n",
    "from config_attack import *\n",
    "from models.unet import UNet\n",
    "from models.attack import Attack, AttackNet\n",
    "from models.classifier import ClassifierNet\n",
    "from dataset import image_from_json, image_list_folder\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    checkpoint_name = 'Attack targeted: {} weight: {} loss_mode: {}'.format(targeted, weight, loss_mode)\n",
    "    comment = 'Attack targeted: {} weight: {} loss_mode: {}'.format(targeted, weight, loss_mode)\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, devices))\n",
    "\n",
    "    mean_arr = [0.5, 0.5, 0.5]\n",
    "    stddev_arr = [0.5, 0.5, 0.5]\n",
    "    normalize = tv.transforms.Normalize(mean=mean_arr,\n",
    "                                     std=stddev_arr)\n",
    "    \n",
    "    train_transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize(image_size),\n",
    "        tv.transforms.ToTensor(),\n",
    "        normalize, \n",
    "    ])\n",
    "\n",
    "    test_transform = tv.transforms.Compose([\n",
    "        tv.transforms.Resize(image_size),\n",
    "        tv.transforms.ToTensor(),\n",
    "        normalize, \n",
    "    ])\n",
    "\n",
    "        \n",
    "    train_dataset = image_from_json.ImageDataSet(\n",
    "        'data/IJCAI_2019_AAAC_train/train_info.json', transform=train_transform)\n",
    "    train_sampler = torch.utils.data.sampler.RandomSampler(\n",
    "        train_dataset, True, num_classes * epoch_size)\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, num_workers=16, batch_size=train_batch_size, sampler=train_sampler)\n",
    "\n",
    "    vali_dataset = image_from_json.ImageDataSet(\n",
    "        'data/IJCAI_2019_AAAC_train/vali_info.json', transform=test_transform)\n",
    "    vali_sampler = torch.utils.data.sampler.RandomSampler(\n",
    "        vali_dataset, True, num_classes * epoch_size)\n",
    "    vali_loader = torch.utils.data.DataLoader(\n",
    "        vali_dataset, num_workers=16, batch_size=test_batch_size, sampler=vali_sampler)\n",
    "    \n",
    "    test_dataset = image_list_folder.ImageListFolder(\n",
    "        root='data/dev_data/', transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, num_workers=16, batch_size=test_batch_size,\n",
    "                                              shuffle=True, drop_last=False)\n",
    "    \n",
    "    model = [pretrainedmodels.__dict__[i](pretrained=None) for i in classifier_name]\n",
    "    classifier = [ClassifierNet(i, num_classes) for i in model]\n",
    "    for c, p in zip(classifier, classifier_path):\n",
    "        c.load_state_dict(torch.load(p))\n",
    "\n",
    "    unet = UNet(n_classes=2 * num_classes * 3)\n",
    "    attack_net = AttackNet(unet)\n",
    "    solver = Attack(attack_net, classifier, train_loader, test_loader, test_batch_size, num_classes=num_classes, \n",
    "                    loss_mode=loss_mode, weight=weight, \n",
    "                    lr=lr, checkpoint_name=checkpoint_name, devices=devices, optimizer=optimizer, targeted=targeted)\n",
    "    if checkpoint_path:\n",
    "        solver.load_model(checkpoint_path)\n",
    "#     with SummaryWriter(comment=comment) as writer:\n",
    "#         solver.train(max_epoch, writer, epoch_size=math.ceil(num_classes * epoch_size / train_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import os\n",
    "import csv\n",
    "import math\n",
    "import glob\n",
    "import tqdm\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torchvision as tv\n",
    "\n",
    "from models import ddn\n",
    "import pretrainedmodels\n",
    "from config_ddn import *\n",
    "from models.classifier import ClassifierNet, Classifier\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = ','.join(map(str, devices))\n",
    "    models = [pretrainedmodels.__dict__[name](pretrained=None) for name in classifier_name]\n",
    "    classifiers = [ClassifierNet(model, num_classes) for model in models]\n",
    "    for c, p in zip(classifiers, classifier_path):\n",
    "        c.load_state_dict(torch.load(p))\n",
    "        c.eval()\n",
    "        c = c.cuda()\n",
    "        \n",
    "    data = {'image_path': [], 'target': [], 'imgs': []}\n",
    "    with open(os.path.join(data_path, 'dev.csv'), 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            img_path = os.path.join(data_path, row['filename'])\n",
    "            data['image_path'].append(img_path)\n",
    "            data['imgs'].append(Image.open(img_path))\n",
    "            if targeted:\n",
    "                data['target'].append(int(row['targetedLabel']))\n",
    "            else:\n",
    "                data['target'].append(int(row['trueLabel']))\n",
    "                \n",
    "    transfrom = tv.transforms.Compose([\n",
    "        tv.transforms.Resize((224, 224)),\n",
    "        tv.transforms.ToTensor(),\n",
    "    #     tv.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "#     attacker = ddn.DDN(steps=steps, device=torch.device('cuda: 0'))\n",
    "#     epoch = math.ceil(len(data['imgs']) / batch_size)\n",
    "#     result = []\n",
    "#     for i in tqdm.tqdm(range(epoch), total=epoch):\n",
    "#         torch.cuda.empty_cache()\n",
    "#         batch_x = data['imgs'][i * batch_size: (i + 1) * batch_size]\n",
    "#         batch_y = data['target'][i * batch_size: (i + 1) * batch_size]\n",
    "        \n",
    "#         batch_x = torch.cat([transfrom(i).unsqueeze(dim=0) for i in batch_x], dim=0).cuda()\n",
    "#         batch_y = torch.tensor(batch_y).cuda()\n",
    "        \n",
    "#         result.append(attacker.attack(classifiers, batch_x, labels=batch_y, \n",
    "#                                       targeted=targeted, use_post_process=use_post_process).detach().cpu().data)\n",
    "#     result = torch.cat(result).numpy()\n",
    "#     result = np.transpose(result, (0, 2, 3, 1))\n",
    "#     result = [Image.fromarray(i) for i in (result * 255).astype(np.uint8)]\n",
    "#     if output_dir is not None:\n",
    "#         if not os.path.exists(output_dir):\n",
    "#             os.mkdir(output_dir)\n",
    "#         for img, path in zip(result, data['image_path']):\n",
    "#             name = path.split('/')[-1]\n",
    "#             path = os.path.join(output_dir, name)\n",
    "#             img = img.resize(output_size)\n",
    "#             img.save(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

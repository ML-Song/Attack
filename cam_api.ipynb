{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import torchvision as tv \n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from models import gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class GAINAPI(object):\n",
    "    def __init__(self, model_path=None, num_classes=110):\n",
    "        mean_arr = [0.5, 0.5, 0.5]\n",
    "        stddev_arr = [0.5, 0.5, 0.5]\n",
    "        normalize = tv.transforms.Normalize(mean=mean_arr,\n",
    "                                         std=stddev_arr)\n",
    "\n",
    "        model_dimension = 224\n",
    "        center_crop = 224\n",
    "        self.data_transform = tv.transforms.Compose([\n",
    "            tv.transforms.Resize(model_dimension),\n",
    "            tv.transforms.CenterCrop(center_crop),\n",
    "            tv.transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])\n",
    "        self.model = gain.GAIN(num_classes).cuda()\n",
    "            \n",
    "        if model_path is not None:\n",
    "            self.model.load_state_dict(torch.load(model_path))\n",
    "        self.model.eval()\n",
    "        self.softmask = gain.SoftMask()\n",
    "        \n",
    "    def __call__(self, img):\n",
    "        with torch.no_grad():\n",
    "            x = self.data_transform(img).unsqueeze(0).cuda()\n",
    "            n, c, h, w = x.shape\n",
    "            out, out_masked, cam = self.model(x)\n",
    "            cam = cam.cpu().squeeze().numpy()\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/common/miniconda3/envs/python3.7_pytorch/lib/python3.6/site-packages/torch/nn/functional.py:1332: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "gain_api = GAINAPI('saved_models/best_GAIN with_transform: False.pt')\n",
    "img = Image.open('data/IJCAI_2019_AAAC_train/00010/1b1a6cab245cd68a4065f86d219ca4f9.jpg')\n",
    "img_np = np.array(img)\n",
    "cam = gain_api(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cam > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
